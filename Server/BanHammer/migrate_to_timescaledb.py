#!/usr/bin/env python3
"""
BanHammer ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜: SQLite â†’ TimescaleDB
5ì²œë§Œëª…+ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import asyncpg
import sqlite3
import psycopg2
import os
import sys
from datetime import datetime, timedelta
import json
import logging
from typing import Dict, List, Tuple
from tqdm import tqdm

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TimescaleMigration:
    """SQLite/PostgreSQL â†’ TimescaleDB ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    def __init__(self, source_db_path: str, timescale_url: str):
        self.source_db_path = source_db_path
        self.timescale_url = timescale_url
        self.batch_size = 10000  # ë°°ì¹˜ í¬ê¸°
        
    async def run_migration(self):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤"""
        logger.info("ğŸš€ TimescaleDB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        try:
            # 1. TimescaleDB ì—°ê²° ë° ì´ˆê¸°í™”
            await self.init_timescaledb()
            
            # 2. ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            await self.migrate_players()
            await self.migrate_actions()
            await self.migrate_violations()
            
            # 3. ì¸ë±ìŠ¤ ë° ì—°ì† ì§‘ê³„ë·° ìƒì„±
            await self.create_continuous_aggregates()
            
            # 4. ë°ì´í„° ê²€ì¦
            await self.verify_migration()
            
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    async def init_timescaledb(self):
        """TimescaleDB ì´ˆê¸°í™”"""
        logger.info("TimescaleDB ì´ˆê¸°í™” ì¤‘...")
        
        conn = await asyncpg.connect(self.timescale_url)
        
        try:
            # TimescaleDB í™•ì¥ ì„¤ì¹˜
            await conn.execute("CREATE EXTENSION IF NOT EXISTS timescaledb;")
            
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ì¬ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)
            await conn.execute("DROP TABLE IF EXISTS player_actions_ts CASCADE;")
            await conn.execute("DROP TABLE IF EXISTS violations_ts CASCADE;")
            await conn.execute("DROP TABLE IF EXISTS player_summary CASCADE;")
            
            # í…Œì´ë¸” ìƒì„±
            await self.create_tables(conn)
            
            # í•˜ì´í¼í…Œì´ë¸” ìƒì„±
            await conn.execute("""
                SELECT create_hypertable('player_actions_ts', 'time', 
                    chunk_time_interval => INTERVAL '1 day',
                    if_not_exists => TRUE);
            """)
            
            await conn.execute("""
                SELECT create_hypertable('violations_ts', 'time',
                    chunk_time_interval => INTERVAL '1 week', 
                    if_not_exists => TRUE);
            """)
            
            logger.info("âœ… TimescaleDB ì´ˆê¸°í™” ì™„ë£Œ")
            
        finally:
            await conn.close()
    
    async def create_tables(self, conn: asyncpg.Connection):
        """í…Œì´ë¸” ìƒì„±"""
        # í”Œë ˆì´ì–´ ì•¡ì…˜ í•˜ì´í¼í…Œì´ë¸”
        await conn.execute("""
            CREATE TABLE player_actions_ts (
                time TIMESTAMPTZ NOT NULL,
                player_id TEXT NOT NULL,
                action_type TEXT NOT NULL,
                value DOUBLE PRECISION DEFAULT 0,
                metadata JSONB
            );
        """)
        
        # ìœ„ë°˜ ì‚¬í•­ í•˜ì´í¼í…Œì´ë¸”
        await conn.execute("""
            CREATE TABLE violations_ts (
                time TIMESTAMPTZ NOT NULL,
                player_id TEXT NOT NULL,
                violation_type TEXT NOT NULL,
                severity DOUBLE PRECISION NOT NULL,
                details JSONB,
                resolved BOOLEAN DEFAULT FALSE
            );
        """)
        
        # í”Œë ˆì´ì–´ ìš”ì•½ í…Œì´ë¸”
        await conn.execute("""
            CREATE TABLE player_summary (
                player_id TEXT PRIMARY KEY,
                username TEXT,
                created_at TIMESTAMPTZ DEFAULT NOW(),
                last_activity TIMESTAMPTZ DEFAULT NOW(),
                current_risk_score DOUBLE PRECISION DEFAULT 0.0,
                total_actions_today INTEGER DEFAULT 0,
                total_violations_today INTEGER DEFAULT 0,
                is_banned BOOLEAN DEFAULT FALSE,
                ban_reason TEXT,
                ban_timestamp TIMESTAMPTZ,
                updated_at TIMESTAMPTZ DEFAULT NOW()
            );
        """)
    
    async def migrate_players(self):
        """í”Œë ˆì´ì–´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("í”Œë ˆì´ì–´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        # SQLite ì—°ê²°
        sqlite_conn = sqlite3.connect(self.source_db_path)
        sqlite_conn.row_factory = sqlite3.Row
        
        # TimescaleDB ì—°ê²°
        ts_conn = await asyncpg.connect(self.timescale_url)
        
        try:
            # í”Œë ˆì´ì–´ ìˆ˜ í™•ì¸
            total_players = sqlite_conn.execute("SELECT COUNT(*) FROM players").fetchone()[0]
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜í•  í”Œë ˆì´ì–´: {total_players:,}ëª…")
            
            if total_players == 0:
                logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜í•  í”Œë ˆì´ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë°°ì¹˜ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
            offset = 0
            progress_bar = tqdm(total=total_players, desc="í”Œë ˆì´ì–´")
            
            while offset < total_players:
                players = sqlite_conn.execute("""
                    SELECT id, username, created_at, last_activity, risk_score, 
                           is_banned, ban_reason, ban_timestamp
                    FROM players
                    LIMIT ? OFFSET ?
                """, (self.batch_size, offset)).fetchall()
                
                if not players:
                    break
                
                # TimescaleDBì— ë°°ì¹˜ ì‚½ì…
                values = []
                for player in players:
                    values.append((
                        player['id'],
                        player['username'],
                        self.parse_datetime(player['created_at']),
                        self.parse_datetime(player['last_activity']),
                        player['risk_score'] or 0.0,
                        0,  # total_actions_today
                        0,  # total_violations_today
                        bool(player['is_banned']),
                        player['ban_reason'],
                        self.parse_datetime(player['ban_timestamp']) if player['ban_timestamp'] else None
                    ))
                
                await ts_conn.executemany("""
                    INSERT INTO player_summary (
                        player_id, username, created_at, last_activity, 
                        current_risk_score, total_actions_today, total_violations_today,
                        is_banned, ban_reason, ban_timestamp
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                """, values)
                
                offset += self.batch_size
                progress_bar.update(len(players))
            
            progress_bar.close()
            logger.info("âœ… í”Œë ˆì´ì–´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        finally:
            sqlite_conn.close()
            await ts_conn.close()
    
    async def migrate_actions(self):
        """ì•¡ì…˜ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ì•¡ì…˜ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        sqlite_conn = sqlite3.connect(self.source_db_path)
        sqlite_conn.row_factory = sqlite3.Row
        ts_conn = await asyncpg.connect(self.timescale_url)
        
        try:
            # ì•¡ì…˜ ìˆ˜ í™•ì¸
            total_actions = sqlite_conn.execute("SELECT COUNT(*) FROM player_actions").fetchone()[0]
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜í•  ì•¡ì…˜: {total_actions:,}ê°œ")
            
            if total_actions == 0:
                logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜í•  ì•¡ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
            offset = 0
            progress_bar = tqdm(total=total_actions, desc="ì•¡ì…˜")
            
            while offset < total_actions:
                actions = sqlite_conn.execute("""
                    SELECT player_id, action_type, timestamp, value, metadata
                    FROM player_actions
                    ORDER BY timestamp
                    LIMIT ? OFFSET ?
                """, (self.batch_size, offset)).fetchall()
                
                if not actions:
                    break
                
                # TimescaleDBì— ë°°ì¹˜ ì‚½ì…
                values = []
                for action in actions:
                    metadata = None
                    if action['metadata']:
                        try:
                            metadata = json.loads(action['metadata'])
                        except:
                            metadata = {"raw": action['metadata']}
                    
                    values.append((
                        self.parse_datetime(action['timestamp']),
                        action['player_id'],
                        action['action_type'],
                        action['value'] or 0.0,
                        json.dumps(metadata) if metadata else None
                    ))
                
                await ts_conn.executemany("""
                    INSERT INTO player_actions_ts (time, player_id, action_type, value, metadata)
                    VALUES ($1, $2, $3, $4, $5)
                """, values)
                
                offset += self.batch_size
                progress_bar.update(len(actions))
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if offset % (self.batch_size * 10) == 0:
                    await asyncio.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°
            
            progress_bar.close()
            logger.info("âœ… ì•¡ì…˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        finally:
            sqlite_conn.close()
            await ts_conn.close()
    
    async def migrate_violations(self):
        """ìœ„ë°˜ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ìœ„ë°˜ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        sqlite_conn = sqlite3.connect(self.source_db_path)
        sqlite_conn.row_factory = sqlite3.Row
        ts_conn = await asyncpg.connect(self.timescale_url)
        
        try:
            total_violations = sqlite_conn.execute("SELECT COUNT(*) FROM violations").fetchone()[0]
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìœ„ë°˜: {total_violations:,}ê°œ")
            
            if total_violations == 0:
                logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìœ„ë°˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            offset = 0
            progress_bar = tqdm(total=total_violations, desc="ìœ„ë°˜")
            
            while offset < total_violations:
                violations = sqlite_conn.execute("""
                    SELECT player_id, violation_type, severity, timestamp, details, resolved
                    FROM violations
                    ORDER BY timestamp
                    LIMIT ? OFFSET ?
                """, (self.batch_size, offset)).fetchall()
                
                if not violations:
                    break
                
                values = []
                for violation in violations:
                    details = None
                    if violation['details']:
                        try:
                            details = json.loads(violation['details'])
                        except:
                            details = {"raw": violation['details']}
                    
                    values.append((
                        self.parse_datetime(violation['timestamp']),
                        violation['player_id'],
                        violation['violation_type'],
                        violation['severity'],
                        json.dumps(details) if details else None,
                        bool(violation['resolved'])
                    ))
                
                await ts_conn.executemany("""
                    INSERT INTO violations_ts (time, player_id, violation_type, severity, details, resolved)
                    VALUES ($1, $2, $3, $4, $5, $6)
                """, values)
                
                offset += self.batch_size
                progress_bar.update(len(violations))
            
            progress_bar.close()
            logger.info("âœ… ìœ„ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        finally:
            sqlite_conn.close()
            await ts_conn.close()
    
    async def create_continuous_aggregates(self):
        """ì—°ì† ì§‘ê³„ë·° ë° ì¸ë±ìŠ¤ ìƒì„±"""
        logger.info("ì—°ì† ì§‘ê³„ë·° ìƒì„± ì¤‘...")
        
        conn = await asyncpg.connect(self.timescale_url)
        
        try:
            # ì¸ë±ìŠ¤ ìƒì„±
            await conn.execute("""
                CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_player_time_desc 
                ON player_actions_ts (player_id, time DESC);
            """)
            
            await conn.execute("""
                CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_action_type_time
                ON player_actions_ts (action_type, time);
            """)
            
            # ì—°ì† ì§‘ê³„ë·° ìƒì„±
            await conn.execute("""
                CREATE MATERIALIZED VIEW IF NOT EXISTS action_stats_1min
                WITH (timescaledb.continuous) AS
                SELECT
                    time_bucket('1 minute', time) AS bucket,
                    action_type,
                    player_id,
                    COUNT(*) as action_count,
                    SUM(value) as total_value,
                    AVG(value) as avg_value,
                    MAX(value) as max_value
                FROM player_actions_ts
                GROUP BY bucket, action_type, player_id;
            """)
            
            # ìë™ ì—…ë°ì´íŠ¸ ì •ì±…
            await conn.execute("""
                SELECT add_continuous_aggregate_policy('action_stats_1min',
                    start_offset => INTERVAL '1 hour',
                    end_offset => INTERVAL '1 minute',
                    schedule_interval => INTERVAL '1 minute');
            """)
            
            # ë°ì´í„° ë³´ì¡´ ì •ì±…
            await conn.execute("""
                SELECT add_retention_policy('player_actions_ts', INTERVAL '90 days');
            """)
            
            await conn.execute("""
                SELECT add_retention_policy('violations_ts', INTERVAL '1 year');
            """)
            
            logger.info("âœ… ì—°ì† ì§‘ê³„ë·° ìƒì„± ì™„ë£Œ")
            
        finally:
            await conn.close()
    
    async def verify_migration(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦"""
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ê²€ì¦ ì¤‘...")
        
        sqlite_conn = sqlite3.connect(self.source_db_path)
        ts_conn = await asyncpg.connect(self.timescale_url)
        
        try:
            # í”Œë ˆì´ì–´ ìˆ˜ ë¹„êµ
            sqlite_players = sqlite_conn.execute("SELECT COUNT(*) FROM players").fetchone()[0]
            ts_players = await ts_conn.fetchval("SELECT COUNT(*) FROM player_summary")
            
            # ì•¡ì…˜ ìˆ˜ ë¹„êµ
            sqlite_actions = sqlite_conn.execute("SELECT COUNT(*) FROM player_actions").fetchone()[0]
            ts_actions = await ts_conn.fetchval("SELECT COUNT(*) FROM player_actions_ts")
            
            # ìœ„ë°˜ ìˆ˜ ë¹„êµ
            sqlite_violations = sqlite_conn.execute("SELECT COUNT(*) FROM violations").fetchone()[0]
            ts_violations = await ts_conn.fetchval("SELECT COUNT(*) FROM violations_ts")
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ê²°ê³¼:")
            logger.info(f"  í”Œë ˆì´ì–´: {sqlite_players:,} â†’ {ts_players:,} ({'âœ…' if sqlite_players == ts_players else 'âŒ'})")
            logger.info(f"  ì•¡ì…˜: {sqlite_actions:,} â†’ {ts_actions:,} ({'âœ…' if sqlite_actions == ts_actions else 'âŒ'})")
            logger.info(f"  ìœ„ë°˜: {sqlite_violations:,} â†’ {ts_violations:,} ({'âœ…' if sqlite_violations == ts_violations else 'âŒ'})")
            
            # ìƒ˜í”Œ ë°ì´í„° ê²€ì¦
            sample_player = await ts_conn.fetchrow("SELECT * FROM player_summary LIMIT 1")
            sample_action = await ts_conn.fetchrow("SELECT * FROM player_actions_ts LIMIT 1")
            
            if sample_player and sample_action:
                logger.info("âœ… ìƒ˜í”Œ ë°ì´í„° ê²€ì¦ ì„±ê³µ")
            else:
                logger.warning("âš ï¸ ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                
        finally:
            sqlite_conn.close()
            await ts_conn.close()
    
    def parse_datetime(self, dt_str) -> datetime:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        if not dt_str:
            return datetime.now()
        
        try:
            # SQLite datetime í˜•ì‹ë“¤ ì§€ì›
            formats = [
                '%Y-%m-%d %H:%M:%S.%f',
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d',
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(dt_str, fmt)
                except ValueError:
                    continue
            
            # Unix timestamp ì‹œë„
            return datetime.fromtimestamp(float(dt_str))
            
        except:
            return datetime.now()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ DB URL ì½ê¸°
    source_db = os.getenv("SOURCE_DB_PATH", "./banhammer.db")
    timescale_url = os.getenv("TIMESCALEDB_URL", "postgresql://user:password@localhost:5432/banhammer_ts")
    
    if not os.path.exists(source_db):
        logger.error(f"ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_db}")
        sys.exit(1)
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   BanHammer â†’ TimescaleDB                    â•‘
â•‘                    ëŒ€ìš©ëŸ‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ì†ŒìŠ¤: {source_db:<50} â•‘
â•‘  ëŒ€ìƒ: TimescaleDB (5ì²œë§Œëª…+ ì§€ì›)                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migration = TimescaleMigration(source_db, timescale_url)
    await migration.run_migration()

if __name__ == "__main__":
    asyncio.run(main())