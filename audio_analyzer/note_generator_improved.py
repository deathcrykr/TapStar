#!/usr/bin/env python3
"""
ì „ë¬¸ì ì¸ ë¦¬ë“¬ ê²Œì„ ë…¸íŠ¸ ìƒì„±ê¸° - ê°œì„  ë²„ì „
ë¦¬ë“¬ ê²Œì„ ì»¤ë®¤ë‹ˆí‹° ê°€ì´ë“œë¼ì¸ ë° ì „ë¬¸ ì›ì¹™ ì ìš©:
1. ê°•í•œ ë¹„íŠ¸(ë“œëŸ¼/ë² ì´ìŠ¤) ì¤‘ì‹¬ ë…¸íŠ¸ ë°°ì¹˜
2. ì˜¤ë²„ì°¨íŒ… ë°©ì§€ ë° ìŒì•…ì„± ê°•ì¡°  
3. í™€ë“œ ë…¸íŠ¸ë¡œ ì§€ì†ìŒ í‘œí˜„
4. ë‚œì´ë„ë³„ íŒ¨í„´ ë³µì¡ë„ ì¡°ì ˆ
5. ì´ì§€ ëª¨ë“œì—ì„œë„ ì¶©ë¶„í•œ ë¦¬ë“¬ê° ë³´ì¥
6. ë³´ì»¬ êµ¬ì—­í™”: vocal, sub_vocal, rap, ttaechang(ë•Œì°½) ìë™ ë¶„ë¥˜
"""

import librosa
import numpy as np
import json
import os
import sys
from scipy.signal import find_peaks
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

class ProfessionalRhythmNoteGenerator:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        
    def analyze_vocal_sections(self, y, sr):
        """ìŒì„±í•™ì  íŠ¹ì„±ì„ ë¶„ì„í•´ì„œ ë³´ì»¬ êµ¬ì—­ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        print("   ğŸ¤ Analyzing vocal sections...")
        
        # 1. ë³´ì»¬ ë¶„ë¦¬ (ì „ê²½/ë°°ê²½)
        S_full, phase = librosa.magphase(librosa.stft(y))
        S_filter = librosa.decompose.nn_filter(S_full, 
                                               aggregate=np.median, 
                                               metric='cosine',
                                               width=int(librosa.time_to_frames(2, sr=sr)))
        S_filter = np.minimum(S_full, S_filter)
        
        # ë³´ì»¬ ë§ˆìŠ¤í¬ ìƒì„±
        margin_v = 10
        power = 2
        mask_v = librosa.util.softmask(S_full - S_filter, margin_v * S_filter, power=power)
        S_vocal = mask_v * S_full
        y_vocal = librosa.istft(S_vocal * phase)
        
        # 2. ìŒì„± íŠ¹ì„± ë¶„ì„ì„ ìœ„í•œ íŠ¹ì§• ì¶”ì¶œ
        hop_length = 512
        frame_length = 2048
        
        # ê¸°ë³¸ íŠ¹ì§•ë“¤
        mfcc = librosa.feature.mfcc(y=y_vocal, sr=sr, n_mfcc=13, hop_length=hop_length)
        chroma = librosa.feature.chroma_stft(y=y_vocal, sr=sr, hop_length=hop_length)
        spectral_centroid = librosa.feature.spectral_centroid(y=y_vocal, sr=sr, hop_length=hop_length)
        zero_crossing_rate = librosa.feature.zero_crossing_rate(y_vocal, frame_length=frame_length, hop_length=hop_length)
        spectral_flatness = librosa.feature.spectral_flatness(y=y_vocal, hop_length=hop_length)
        rms_energy = librosa.feature.rms(y=y_vocal, hop_length=hop_length)
        
        # í”¼ì¹˜ ì•ˆì •ì„± ë¶„ì„
        pitches, magnitudes = librosa.piptrack(y=y_vocal, sr=sr, hop_length=hop_length)
        pitch_values = []
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t] if magnitudes[index, t] > 0.1 else 0
            pitch_values.append(pitch)
        pitch_stability = np.std(pitch_values)
        
        # í…œí¬ê·¸ë¨ (ë¦¬ë“¬ ë¶„ì„)  
        tempo, beats = librosa.beat.beat_track(y=y_vocal, sr=sr)
        tempogram = librosa.feature.tempogram(y=y_vocal, sr=sr)
        
        # 3. ì‹œê°„ ì¶• ìƒì„±
        times = librosa.frames_to_time(np.arange(chroma.shape[1]), sr=sr, hop_length=hop_length)
        
        # 4. êµ¬ê°„ë³„ íŠ¹ì§• ë²¡í„° ìƒì„± (2ì´ˆ ìœˆë„ìš°)
        window_size = int(2 * sr / hop_length)  # 2ì´ˆ
        sections = []
        
        for i in range(0, len(times), window_size // 2):  # 50% ì˜¤ë²„ë©
            if i + window_size >= len(times):
                break
                
            start_idx = i
            end_idx = min(i + window_size, len(times))
            start_time = times[start_idx]
            end_time = times[end_idx - 1]
            
            # êµ¬ê°„ë³„ íŠ¹ì§• ê³„ì‚°
            section_features = self._extract_section_features(
                mfcc[:, start_idx:end_idx],
                chroma[:, start_idx:end_idx], 
                spectral_centroid[:, start_idx:end_idx],
                zero_crossing_rate[:, start_idx:end_idx],
                spectral_flatness[:, start_idx:end_idx],
                rms_energy[:, start_idx:end_idx]
            )
            
            # êµ¬ê°„ ë¶„ë¥˜
            section_type = self._classify_vocal_section(section_features)
            
            sections.append({
                'start_time': float(start_time),
                'end_time': float(end_time),
                'type': section_type,
                'features': section_features
            })
        
        print(f"   âœ… Detected {len(sections)} vocal sections")
        return sections
    
    def _extract_section_features(self, mfcc, chroma, spectral_centroid, zcr, flatness, rms):
        """êµ¬ê°„ë³„ ìŒì„± íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        features = {}
        
        # MFCC í†µê³„
        features['mfcc_mean'] = float(np.mean(mfcc))
        features['mfcc_std'] = float(np.std(mfcc))
        features['mfcc_delta_mean'] = float(np.mean(np.diff(mfcc, axis=1)))
        
        # í¬ë¡œë§ˆ (í™”ì„±/ë©œë¡œë””)
        features['chroma_strength'] = float(np.mean(np.max(chroma, axis=0)))
        features['chroma_std'] = float(np.std(chroma))
        
        # ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì„±
        features['spectral_centroid_mean'] = float(np.mean(spectral_centroid))
        features['spectral_centroid_std'] = float(np.std(spectral_centroid))
        
        # ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨ (ì–¸ì–´ì  íŠ¹ì„±)
        features['zcr_mean'] = float(np.mean(zcr))
        features['zcr_std'] = float(np.std(zcr))
        
        # ìŠ¤í™íŠ¸ëŸ´ í‰íƒ„ë„ (í™”ì„±ì„±)
        features['flatness_mean'] = float(np.mean(flatness))
        features['flatness_std'] = float(np.std(flatness))
        
        # RMS ì—ë„ˆì§€
        features['rms_mean'] = float(np.mean(rms))
        features['rms_std'] = float(np.std(rms))
        
        # ë¦¬ë“¬ê° (ì—ë„ˆì§€ ë³€í™”)
        features['energy_variation'] = float(np.std(rms) / (np.mean(rms) + 1e-8))
        
        return features
    
    def _classify_vocal_section(self, features):
        """ìŒì„±í•™ì  íŠ¹ì§•ìœ¼ë¡œ ë³´ì»¬ ì„¹ì…˜ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        
        # ì‹¤ì œ ìŒì•… ë°ì´í„° ê¸°ë°˜ ì¡°ì •ëœ ë¶„ë¥˜ ê¸°ì¤€
        
        # ë© íŒë³„: ë†’ì€ ZCR, ë†’ì€ ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ, ë†’ì€ ì—ë„ˆì§€ ë³€í™”
        is_rap = (features['zcr_mean'] > 0.18 and 
                  features['spectral_centroid_mean'] > 5000 and
                  features['energy_variation'] > 0.95 and
                  features['mfcc_delta_mean'] > 0.05)  # ë¹ ë¥¸ ìŒì„± ë³€í™”
        
        # ë•Œì°½/ì½”ëŸ¬ìŠ¤ íŒë³„: ë†’ì€ ì—ë„ˆì§€, ë†’ì€ í™”ì„±ì„±, ì•ˆì •ëœ í”¼ì¹˜
        is_ttaechang = (features['rms_mean'] > 0.02 and
                        features['chroma_strength'] >= 0.95 and
                        features['flatness_mean'] < 0.0002 and
                        features['energy_variation'] > 0.9 and
                        features['zcr_std'] < 0.15)  # ì•ˆì •ëœ ìŒì„±
        
        # ì„œë¸Œ ë³´ì»¬ íŒë³„: ë‚®ì€ ì—ë„ˆì§€, ë‚®ì€ ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ, ì•ˆì •ì„±
        is_sub_vocal = (features['rms_mean'] < 0.014 and
                        features['spectral_centroid_mean'] < 4500 and
                        features['zcr_mean'] < 0.17 and
                        features['energy_variation'] < 0.90 and
                        features['mfcc_delta_mean'] < 0.05)  # ëŠë¦° ìŒì„± ë³€í™”
        
        # ë¶„ë¥˜ ìš°ì„ ìˆœìœ„ (ë” êµ¬ì²´ì ì¸ ê²ƒë¶€í„°)
        if is_rap:
            return 'rap'
        elif is_ttaechang:
            return 'ttaechang'
        elif is_sub_vocal:
            return 'sub_vocal'
        else:
            return 'vocal'  # ê¸°ë³¸ ë³´ì»¬
        
    def generate_notes(self, mp3_file_path):
        """MP3 íŒŒì¼ì—ì„œ ì „ë¬¸ì ì¸ ë¦¬ë“¬ê²Œì„ ë…¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        if not os.path.exists(mp3_file_path):
            raise FileNotFoundError(f"MP3 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mp3_file_path}")
        
        print(f"ğŸµ Professional Rhythm Analysis: {os.path.basename(mp3_file_path)}")
        
        # ìŒì•… ë¡œë“œ
        y, sr = librosa.load(mp3_file_path, duration=None, sr=self.sample_rate)
        duration = len(y) / sr
        print(f"   Duration: {duration:.1f}s")
        
        # í…œí¬ì™€ ë¹„íŠ¸ ë¶„ì„
        tempo, beats = self._analyze_tempo_and_beats(y, sr)
        print(f"   BPM: {tempo:.1f}, Beats: {len(beats)}")
        
        # ìŒì•… êµ¬ì¡° ë¶„ì„ (Principle 1: ê°•í•œ ë¹„íŠ¸ ê°•ì¡°)
        musical_elements = self._analyze_musical_elements(y, sr, beats, tempo)
        print(f"   Musical Elements Analyzed")
        
        # ë³´ì»¬ êµ¬ì—­ ë¶„ì„ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        vocal_sections = self.analyze_vocal_sections(y, sr)
        musical_elements['vocal_sections'] = vocal_sections
        
        # ì „ë¬¸ì ì¸ ë…¸íŠ¸ ìƒì„± (ëª¨ë“  ì›ì¹™ í†µí•©)
        all_notes = self._generate_professional_notes(y, sr, beats, tempo, musical_elements, duration)
        print(f"   Generated {len(all_notes)} notes with professional design")
        
        # ë…¸íŠ¸ ì •ë³´ ë¶„ì„ ë° ìš”ì•½ ì¶œë ¥
        self._print_note_analysis_summary(all_notes, tempo, duration, vocal_sections)
        
        # ì°¨íŠ¸ ë°ì´í„° êµ¬ì„±
        mp3_filename = os.path.basename(mp3_file_path)
        chart = self._create_professional_chart_data(tempo, sr, all_notes, mp3_filename, musical_elements)
        
        # íŒŒì¼ ì €ì¥
        output_file = self._get_output_filename(mp3_file_path)
        self._save_chart(chart, output_file)
        
        print(f"âœ… Professional Chart Created: {output_file}")
        return output_file
    
    def _analyze_tempo_and_beats(self, y, sr):
        """ì •í™•í•œ í…œí¬ì™€ ë¹„íŠ¸ ë¶„ì„"""
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr, units='time', hop_length=512)
        tempo_val = float(tempo[0]) if hasattr(tempo, '__len__') else float(tempo)
        return tempo_val, beats
    
    def _analyze_musical_elements(self, y, sr, beats, tempo):
        """ìŒì•…ì˜ í•µì‹¬ ìš”ì†Œ ë¶„ì„ (Principle 1: ê°•í•œ ë¹„íŠ¸ ê°•ì¡°)"""
        print("   ğŸ¯ Analyzing Core Musical Elements...")
        
        # 1. ë“œëŸ¼/í¼ì»¤ì…˜ ë¶„ì„ (20-250Hz)
        drum_strength = self._analyze_frequency_band(y, sr, 20, 250, "drums")
        
        # 2. ë² ì´ìŠ¤ ë¼ì¸ ë¶„ì„ (60-300Hz) 
        bass_strength = self._analyze_frequency_band(y, sr, 60, 300, "bass")
        
        # 3. ë©œë¡œë”” ë¶„ì„ (200-2000Hz)
        melody_strength = self._analyze_frequency_band(y, sr, 200, 2000, "melody")
        
        # 4. ë³´ì»¬/ìƒìœ„ ì£¼íŒŒìˆ˜ ë¶„ì„ (1000-8000Hz)
        vocal_strength = self._analyze_frequency_band(y, sr, 1000, 8000, "vocal")
        
        # 5. ë™ì  ë¶„ì„ (RMS ì—ë„ˆì§€)
        rms_energy = librosa.feature.rms(y=y, hop_length=512)[0]
        
        return {
            'drum_strength': drum_strength,
            'bass_strength': bass_strength, 
            'melody_strength': melody_strength,
            'vocal_strength': vocal_strength,
            'rms_energy': rms_energy,
            'tempo': tempo
        }
    
    def _analyze_frequency_band(self, y, sr, freq_min, freq_max, band_name):
        """íŠ¹ì • ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë¶„ì„"""
        stft = librosa.stft(y, hop_length=512)
        magnitude = np.abs(stft)
        freqs = librosa.fft_frequencies(sr=sr)
        
        freq_mask = (freqs >= freq_min) & (freqs <= freq_max)
        band_strength = np.mean(magnitude[freq_mask], axis=0)
        
        # ì •ê·œí™”
        if np.max(band_strength) > 0:
            band_strength = band_strength / np.max(band_strength)
            
        return band_strength
    
    def _generate_professional_notes(self, y, sr, beats, tempo, musical_elements, duration):
        """ì „ë¬¸ì ì¸ ì›ì¹™ì— ë”°ë¥¸ ë…¸íŠ¸ ìƒì„± - ì°¨íŒ… ê°€ì´ë“œ ê¸°ë°˜"""
        print("   ğŸ¼ Applying Advanced Charting Principles...")
        
        notes = []
        
        # ìŒì•… êµ¬ì¡° ë¶„ì„ (ì„¹ì…˜ë³„ ì²˜ë¦¬)
        sections = self._analyze_music_structure(y, sr, beats, duration)
        
        # ì ì§„ì  ë ˆì´ì–´ë§ (Progressive Layering)
        # 1. ë©”ì¸ í•˜ëª¨ë‹‰ ë¦¬ë“œ (Pitch Relevancy ê¸°ë°˜)
        main_harmonic_notes = self._create_main_harmonic_layer(beats, musical_elements, sections)
        notes.extend(main_harmonic_notes)
        
        # 2. ë“œëŸ¼ & í¼ì»¤ì…˜ ë ˆì´ì–´ (í‚¥/ìŠ¤ë„¤ì–´)
        drum_notes = self._create_drum_layer(beats, musical_elements, sections)
        notes.extend(drum_notes)
        
        # 3. ë³´ì»¬ ë ˆì´ì–´
        vocal_notes = self._create_vocal_layer(y, sr, musical_elements, sections)
        notes.extend(vocal_notes)
        
        # 4. ì„¸ì»¨ë”ë¦¬ ë©œë¡œë”” (Medium/Hardìš©)
        secondary_notes = self._create_secondary_melody_layer(musical_elements, sections)
        notes.extend(secondary_notes)
        
        # ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
        notes.sort(key=lambda x: x["time_seconds"])
        notes = self._remove_overlapping_notes(notes)
        
        # ë ˆë²¨ë³„ ë…¸íŠ¸ ê°œìˆ˜ ê³„ì‚°
        easy_count = len([n for n in notes if n['level']==1])
        medium_count = len([n for n in notes if n['level']==2]) 
        hard_count = len([n for n in notes if n['level']==3])
        
        print(f"     ğŸ“Š ë ˆë²¨ë³„ ë…¸íŠ¸ ê°œìˆ˜:")
        print(f"        Level 1 (Easy)  : {easy_count}ê°œ")
        print(f"        Level 2 (Medium): {medium_count}ê°œ") 
        print(f"        Level 3 (Hard)  : {hard_count}ê°œ")
        print(f"        ì´í•©            : {easy_count + medium_count + hard_count}ê°œ")
        
        return notes
    
    def _analyze_music_structure(self, y, sr, beats, duration):
        """ìŒì•… êµ¬ì¡° ë¶„ì„ - ì¸íŠ¸ë¡œ/ë²ŒìŠ¤/ì½”ëŸ¬ìŠ¤/ë¸Œë¦¿ì§€ ë“± ì„¹ì…˜ êµ¬ë¶„"""
        sections = []
        rms_energy = librosa.feature.rms(y=y, hop_length=512)[0]
        times = librosa.frames_to_time(np.arange(len(rms_energy)), sr=sr, hop_length=512)
        
        # ì—ë„ˆì§€ ë ˆë²¨ë¡œ ì„¹ì…˜ êµ¬ë¶„ (ë‹¨ìˆœí™”ëœ ë²„ì „)
        energy_threshold = np.mean(rms_energy) + np.std(rms_energy) * 0.5
        
        section_start = 0
        current_energy_high = rms_energy[0] > energy_threshold
        
        for i, energy in enumerate(rms_energy):
            is_high_energy = energy > energy_threshold
            
            # ì—ë„ˆì§€ ë ˆë²¨ ë³€í™” ê°ì§€
            if is_high_energy != current_energy_high:
                section_end = times[i]
                section_type = "chorus" if current_energy_high else "verse"
                sections.append({
                    'start': section_start,
                    'end': section_end,
                    'type': section_type,
                    'energy_level': np.mean(rms_energy[max(0, i-50):i+1])
                })
                section_start = section_end
                current_energy_high = is_high_energy
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
        sections.append({
            'start': section_start,
            'end': duration,
            'type': "outro" if len(sections) > 0 else "full",
            'energy_level': np.mean(rms_energy[-50:])
        })
        
        print(f"     ğŸµ Detected {len(sections)} music sections")
        return sections
    
    def _create_main_harmonic_layer(self, beats, musical_elements, sections):
        """ë©”ì¸ í•˜ëª¨ë‹‰ ë¦¬ë“œ ìƒì„± - í”¼ì¹˜ ì—°ê´€ì„±(PR) ê¸°ë°˜"""
        print("     ğŸ¼ Creating Main Harmonic Layer (Pitch Relevancy)...")
        
        notes = []
        melody_strength = musical_elements['melody_strength']
        times = librosa.frames_to_time(np.arange(len(melody_strength)), sr=self.sample_rate, hop_length=512)
        
        for i, beat_time in enumerate(beats):
            # í˜„ì¬ ì„¹ì…˜ ì°¾ê¸°
            current_section = self._find_current_section(beat_time, sections)
            section_modifier = 1.2 if current_section['type'] == 'chorus' else 0.8
            
            time_idx = np.argmin(np.abs(times - beat_time))
            if time_idx < len(melody_strength):
                melody_power = melody_strength[time_idx] * section_modifier
                
                # í”¼ì¹˜ ì—°ê´€ì„±ì„ ìœ„í•œ ë ˆì¸ ê²°ì • (4ë ˆì¸: 0=ë‚®ìŒ, 3=ë†’ìŒ)
                lane = self._determine_pitch_relevant_lane(melody_power, beat_time, i)
                
                # ë©”ì¸ í•˜ëª¨ë‹‰ì€ Easy ë ˆë²¨, ê°•í•œ ë©œë¡œë””ë§Œ
                if melody_power > 0.6:
                    note = self._create_note(
                        beat_time, melody_power, i,
                        note_type="tap", level=1, source="main_harmonic",
                        lane=lane
                    )
                    notes.append(note)
        
        print(f"     âœ… Main Harmonic: {len(notes)} notes with pitch relevancy")
        return notes
    
    def _create_drum_layer(self, beats, musical_elements, sections):
        """ë“œëŸ¼ & í¼ì»¤ì…˜ ë ˆì´ì–´ - í‚¥/ìŠ¤ë„¤ì–´ ì¤‘ì‹¬"""
        print("     ğŸ¥ Creating Drum Layer (Kicks & Snares)...")
        
        notes = []
        drum_strength = musical_elements['drum_strength']
        bass_strength = musical_elements['bass_strength']
        times = librosa.frames_to_time(np.arange(len(drum_strength)), sr=self.sample_rate, hop_length=512)
        
        for i, beat_time in enumerate(beats):
            beat_in_measure = i % 4
            time_idx = np.argmin(np.abs(times - beat_time))
            
            if time_idx < len(drum_strength):
                drum_power = drum_strength[time_idx]
                bass_power = bass_strength[time_idx]
                combined_power = drum_power * 0.8 + bass_power * 0.2
                
                # í‚¥/ìŠ¤ë„¤ì–´ íŒ¨í„´ ìƒì„± (ì¸ê°„ ê³µí•™ì  ì œì•½ ê³ ë ¤)
                should_place = False
                level = 1
                note_type = "tap"
                
                # ê°•í•œ ë‹¤ìš´ë¹„íŠ¸ (í‚¥)
                if beat_in_measure == 0 and combined_power > 0.7:
                    should_place = True
                    lane = 1  # ì¤‘ì•™-ì¢Œì¸¡ (í‚¥)
                    
                # ìŠ¤ë„¤ì–´ (3ë°•)
                elif beat_in_measure == 2 and combined_power > 0.6:
                    should_place = True
                    lane = 2  # ì¤‘ì•™-ìš°ì¸¡ (ìŠ¤ë„¤ì–´)
                    level = 2  # Medium ë‚œì´ë„
                
                # ë³µì¡í•œ ë“œëŸ¼ íŒ¨í„´ (Hard)
                elif combined_power > 0.8:
                    should_place = True
                    lane = 0 if beat_in_measure % 2 == 0 else 3  # ì–‘ìª½ ë
                    level = 3
                
                if should_place and self._is_good_spacing_advanced(beat_time, notes, lane):
                    note = self._create_note(
                        beat_time, combined_power, i,
                        note_type=note_type, level=level, source="drums",
                        lane=lane
                    )
                    notes.append(note)
        
        print(f"     âœ… Drums: {len(notes)} notes with ergonomic patterns")
        return notes
    
    def _create_vocal_layer(self, y, sr, musical_elements, sections):
        """ë³´ì»¬ ë ˆì´ì–´ - ë³´ì»¬ ë¼ì¸ ì¶”ì """
        print("     ğŸ¤ Creating Vocal Layer...")
        
        notes = []
        vocal_strength = musical_elements['vocal_strength']
        times = librosa.frames_to_time(np.arange(len(vocal_strength)), sr=sr, hop_length=512)
        
        # ë³´ì»¬ í”¼í¬ ê°ì§€
        vocal_peaks, _ = find_peaks(vocal_strength, height=0.65, distance=int(sr/512 * 0.3))
        
        for peak_idx in vocal_peaks:
            if peak_idx < len(times):
                peak_time = times[peak_idx]
                strength = vocal_strength[peak_idx]
                
                # í˜„ì¬ ì„¹ì…˜ì˜ íƒ€ì…ì— ë”°ë¼ ë ˆë²¨ ì¡°ì •
                current_section = self._find_current_section(peak_time, sections)
                if current_section['type'] == 'chorus':
                    level = 2  # ì½”ëŸ¬ìŠ¤ì—ì„œ ë³´ì»¬ ê°•ì¡°
                else:
                    level = 3  # ë²„ìŠ¤ì—ì„œëŠ” Hard ë ˆë²¨
                
                # ë³´ì»¬ì€ ë†’ì€ í”¼ì¹˜ì´ë¯€ë¡œ ìƒìœ„ ë ˆì¸ ì‚¬ìš©
                lane = 3 if strength > 0.8 else 2
                
                note = self._create_note(
                    peak_time, strength, 0,
                    note_type="tap", level=level, source="vocal",
                    lane=lane
                )
                notes.append(note)
        
        print(f"     âœ… Vocals: {len(notes)} notes following vocal lines")
        return notes
    
    def _create_secondary_melody_layer(self, musical_elements, sections):
        """ì„¸ì»¨ë”ë¦¬ ë©œë¡œë”” ë ˆì´ì–´ - Medium/Hard ë³µì¡ì„± ì¶”ê°€"""
        print("     ğŸ¹ Creating Secondary Melody Layer...")
        
        notes = []
        melody_strength = musical_elements['melody_strength']
        times = librosa.frames_to_time(np.arange(len(melody_strength)), sr=self.sample_rate, hop_length=512)
        
        # ì„¸ì»¨ë”ë¦¬ ë©œë¡œë”” ê°ì§€ (ì¤‘ê°„ ê°•ë„)
        for i, strength in enumerate(melody_strength):
            if 0.4 < strength < 0.65:  # ì¤‘ê°„ ê°•ë„ ë©œë¡œë””
                time_point = times[i]
                
                # ì„¹ì…˜ë³„ ì²˜ë¦¬
                current_section = self._find_current_section(time_point, sections)
                if current_section['type'] == 'chorus':
                    level = 2  # ì½”ëŸ¬ìŠ¤ì—ì„œëŠ” Medium
                    lane = 1  # ì¤‘ì•™
                else:
                    level = 3  # ê¸°íƒ€ ì„¹ì…˜ì—ì„œëŠ” Hard
                    lane = 0  # ì¢Œì¸¡
                
                # ê°„ê²© ì²´í¬ (ì˜¤ë²„ì°¨íŒ… ë°©ì§€)
                if self._is_good_spacing_advanced(time_point, notes, lane, min_gap=0.2):
                    note = self._create_note(
                        time_point, strength, 0,
                        note_type="tap", level=level, source="secondary_melody",
                        lane=lane
                    )
                    notes.append(note)
        
        print(f"     âœ… Secondary: {len(notes)} notes for complexity")
        return notes
    
    def _find_current_section(self, time_point, sections):
        """í˜„ì¬ ì‹œê°„ì ì— í•´ë‹¹í•˜ëŠ” ìŒì•… ì„¹ì…˜ ì°¾ê¸°"""
        for section in sections:
            if section['start'] <= time_point < section['end']:
                return section
        return sections[-1]  # ê¸°ë³¸ê°’: ë§ˆì§€ë§‰ ì„¹ì…˜
    
    def _determine_pitch_relevant_lane(self, melody_power, beat_time, beat_index):
        """í”¼ì¹˜ ì—°ê´€ì„± ê¸°ë°˜ ë ˆì¸ ê²°ì • (0=ë‚®ìŒ, 3=ë†’ìŒ)"""
        # ë©œë¡œë”” ê°•ë„ì™€ ì‹œê°„ì„ ì¡°í•©í•˜ì—¬ í”¼ì¹˜ ì¶”ì •
        pitch_estimate = melody_power + (beat_time % 8) / 8 * 0.3
        
        if pitch_estimate < 0.3:
            return 0  # ë‚®ì€ í”¼ì¹˜ -> ì¢Œì¸¡
        elif pitch_estimate < 0.6:
            return 1  # ì¤‘ì €ìŒ -> ì¤‘ì•™ ì¢Œ
        elif pitch_estimate < 0.8:
            return 2  # ì¤‘ê³ ìŒ -> ì¤‘ì•™ ìš°
        else:
            return 3  # ë†’ì€ í”¼ì¹˜ -> ìš°ì¸¡
    
    def _is_good_spacing_advanced(self, current_time, existing_notes, target_lane, min_gap=0.15):
        """í–¥ìƒëœ ê°„ê²© ì²´í¬ - ë ˆì¸ë³„ ê°„ê²© ê³ ë ¤"""
        if not existing_notes:
            return True
        
        # ê°™ì€ ë ˆì¸ì˜ ìµœê·¼ ë…¸íŠ¸ë“¤ë§Œ ì²´í¬ (ì­ ë°©ì§€)
        same_lane_notes = [n for n in existing_notes[-5:] if n.get("lane") == target_lane]
        
        for note in same_lane_notes:
            if abs(note["time_seconds"] - current_time) < min_gap:
                return False
        
        # ì „ì²´ ë…¸íŠ¸ì™€ì˜ ìµœì†Œ ê°„ê²©ë„ ì²´í¬
        for note in existing_notes[-3:]:
            if abs(note["time_seconds"] - current_time) < 0.08:
                return False
        
        return True
    
    def _create_core_rhythm_layer(self, beats, tempo, musical_elements, duration):
        """í•µì‹¬ ë¦¬ë“¬ ë ˆì´ì–´ ìƒì„± (Easy ëª¨ë“œ ê¸°ì¤€, ì¶©ë¶„í•œ ë¦¬ë“¬ê° ë³´ì¥)"""
        print("     ğŸ¥ Creating Core Rhythm Layer...")
        
        notes = []
        drum_strength = musical_elements['drum_strength']
        bass_strength = musical_elements['bass_strength']
        
        # ì‹œê°„ í”„ë ˆì„ ë§¤í•‘
        times = librosa.frames_to_time(np.arange(len(drum_strength)), sr=self.sample_rate, hop_length=512)
        
        for i, beat_time in enumerate(beats):
            beat_in_measure = i % 4
            is_downbeat = beat_in_measure == 0  # 1ë°•
            is_strong_beat = beat_in_measure in [0, 2]  # 1ë°•, 3ë°•
            
            # í•´ë‹¹ ì‹œê°„ì˜ ìŒì•… ê°•ë„ ê³„ì‚°
            time_idx = np.argmin(np.abs(times - beat_time))
            if time_idx < len(drum_strength):
                drum_power = drum_strength[time_idx]
                bass_power = bass_strength[time_idx]
                combined_power = (drum_power * 0.7 + bass_power * 0.3)
                
                # Easy ëª¨ë“œì—ì„œë„ ì¶©ë¶„í•œ ë¦¬ë“¬ê°ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ ì„ íƒ (ë” ì—„ê²©í•œ ê¸°ì¤€)
                should_place_note = False
                
                if is_downbeat and combined_power > 0.65:  # 1ë°•ì€ ë§¤ìš° ê°•í•  ë•Œë§Œ
                    should_place_note = True
                elif is_strong_beat and combined_power > 0.8:  # 3ë°•ì€ ê·¹ê°•í•  ë•Œë§Œ
                    should_place_note = True
                elif combined_power > 0.9:  # ê·¹ê°• ë…¸íŠ¸ë§Œ
                    should_place_note = True
                    
                # ì´ì§€ ëª¨ë“œ ë¦¬ë“¬ê° ë³´ì¥: 6ë°•ìë§ˆë‹¤ ìµœì†Œ 1ê°œ ë…¸íŠ¸ (ë” ì—¬ìœ ë¡­ê²Œ)
                if not should_place_note and beat_in_measure == 0:
                    recent_notes = [n for n in notes if abs(n["time_seconds"] - beat_time) < 3.0]  # 3ì´ˆë¡œ í™•ì¥
                    if len(recent_notes) == 0:  # ìµœê·¼ 3ì´ˆê°„ ë…¸íŠ¸ê°€ ì—†ìœ¼ë©´ ê°•ì œ ë°°ì¹˜
                        should_place_note = True
                        combined_power = max(combined_power, 0.6)  # ìµœì†Œ ê°•ë„ ë³´ì¥
                
                if should_place_note and self._is_good_spacing(beat_time, notes, min_gap=0.15):
                    note = self._create_note(
                        beat_time, combined_power, i, 
                        note_type="tap", level=1, source="core_rhythm"
                    )
                    notes.append(note)
        
        print(f"     âœ… Core Rhythm: {len(notes)} notes for solid rhythm foundation")
        return notes
    
    def _create_sustain_holds(self, y, sr, beats, musical_elements, duration):
        """ì§€ì†ìŒì„ ìœ„í•œ í™€ë“œ ë…¸íŠ¸ ìƒì„± (Principle 3)"""
        print("     ğŸµ Creating Sustain Hold Notes...")
        
        notes = []
        melody_strength = musical_elements['melody_strength'] 
        times = librosa.frames_to_time(np.arange(len(melody_strength)), sr=sr, hop_length=512)
        
        # ì§€ì†ìŒ êµ¬ê°„ ê°ì§€
        sustained_regions = []
        current_sustain = None
        threshold = 0.6
        
        for i, time in enumerate(times):
            if i < len(melody_strength) and melody_strength[i] > threshold:
                if current_sustain is None:
                    current_sustain = {'start': time, 'strength': melody_strength[i]}
                else:
                    current_sustain['end'] = time
                    current_sustain['max_strength'] = max(current_sustain.get('max_strength', 0), melody_strength[i])
            else:
                if current_sustain and 'end' in current_sustain:
                    sustain_duration = current_sustain['end'] - current_sustain['start']
                    if sustain_duration >= 0.8:  # 0.8ì´ˆ ì´ìƒë§Œ í™€ë“œ ë…¸íŠ¸ë¡œ
                        sustained_regions.append(current_sustain)
                current_sustain = None
        
        # í™€ë“œ ë…¸íŠ¸ ìƒì„±
        for region in sustained_regions:
            duration_sec = region['end'] - region['start']
            if duration_sec >= 1.0:  # 1ì´ˆ ì´ìƒë§Œ í™€ë“œë¡œ
                note = self._create_note(
                    region['start'], region['max_strength'], 0,
                    note_type="hold", level=1, source="sustain_hold",
                    duration_seconds=min(duration_sec, 3.0)  # ìµœëŒ€ 3ì´ˆ
                )
                notes.append(note)
        
        print(f"     âœ… Sustain Holds: {len(notes)} hold notes for musical expression")
        return notes
    
    def _create_enhancement_layers(self, beats, musical_elements, duration):
        """Medium/Hard ë‚œì´ë„ìš© ì¶”ê°€ ë ˆì´ì–´"""
        print("     ğŸ¯ Creating Enhancement Layers (Medium/Hard)...")
        
        notes = []
        melody_strength = musical_elements['melody_strength']
        vocal_strength = musical_elements['vocal_strength']
        times = librosa.frames_to_time(np.arange(len(melody_strength)), sr=self.sample_rate, hop_length=512)
        
        # Medium ë ˆì´ì–´: ë©œë¡œë”” ê°•ì¡°
        for i, beat_time in enumerate(beats):
            if i < len(times):
                time_idx = np.argmin(np.abs(times - beat_time))
                if time_idx < len(melody_strength):
                    melody_power = melody_strength[time_idx]
                    
                    # Medium ë…¸íŠ¸: ë©œë¡œë””ê°€ ê°•í•  ë•Œ
                    if melody_power > 0.65:
                        note = self._create_note(
                            beat_time, melody_power, i,
                            note_type="tap", level=2, source="melody_accent"
                        )
                        notes.append(note)
        
        # Hard ë ˆì´ì–´: ë³µì¡í•œ íŒ¨í„´ê³¼ ë³´ì»¬ ì•¡ì„¼íŠ¸
        vocal_peaks, _ = find_peaks(vocal_strength, height=0.7, distance=int(self.sample_rate/512 * 0.5))
        vocal_times = times[vocal_peaks] if len(vocal_peaks) > 0 else []
        
        for vocal_time in vocal_times:
            if vocal_time < duration - 0.5:  # ê³¡ ë ì—¬ìœ 
                strength = vocal_strength[np.argmin(np.abs(times - vocal_time))]
                note = self._create_note(
                    vocal_time, strength, 0,
                    note_type="tap", level=3, source="vocal_accent"
                )
                notes.append(note)
        
        print(f"     âœ… Enhancement: {len(notes)} notes for higher difficulties")
        return notes
    
    def _create_artistic_accents(self, musical_elements, beats, duration):
        """ìŒì•…ì  í‘œí˜„ì„ ìœ„í•œ íŠ¹ë³„ ë…¸íŠ¸ (Principle 6: ë…¸íŠ¸ ì•„íŠ¸)"""
        print("     ğŸ¨ Creating Artistic Accents...")
        
        notes = []
        rms_energy = musical_elements['rms_energy']
        times = librosa.frames_to_time(np.arange(len(rms_energy)), sr=self.sample_rate, hop_length=512)
        
        # ë‹¤ì´ë‚˜ë¯¹ ë³€í™” ì§€ì  ê°ì§€ (í¬ë ˆì„¼ë„, ë””ë¯¸ëˆ„ì—”ë„)
        energy_diff = np.diff(rms_energy)
        crescendo_points = find_peaks(energy_diff, height=0.01, distance=int(self.sample_rate/512 * 2))[0]
        
        for peak_idx in crescendo_points:
            if peak_idx < len(times):
                peak_time = times[peak_idx]
                if peak_time < duration - 0.5:
                    strength = rms_energy[peak_idx]
                    
                    # ìŒì•…ì  íë¦„ì„ í‘œí˜„í•˜ëŠ” íŠ¹ë³„ ë…¸íŠ¸
                    note = self._create_note(
                        peak_time, strength, 0,
                        note_type="tap", level=2, source="dynamic_accent"
                    )
                    notes.append(note)
        
        print(f"     âœ… Artistic: {len(notes)} notes for musical expression")
        return notes
    
    def _create_note(self, time_seconds, intensity, beat_index, note_type="tap", level=1, source="rhythm", duration_seconds=None, lane=None):
        """ì „ë¬¸ì ì¸ ë…¸íŠ¸ ìƒì„± - í”¼ì¹˜ ì—°ê´€ì„± ì§€ì›"""
        note = {
            "time_seconds": round(float(time_seconds), 6),  # ë§ˆì´í¬ë¡œì´ˆ ì •ë°€ë„ë¡œ ê°œì„ 
            "time_milliseconds": round(float(time_seconds) * 1000),
            "time_samples": round(float(time_seconds) * self.sample_rate),
            "lane": lane if lane is not None else self._get_professional_lane_placement(time_seconds, intensity, level, source),
            "type": note_type,
            "intensity": round(float(intensity), 2),
            "level": level,
            "source": source
        }
        
        # í™€ë“œ ë…¸íŠ¸ ì •ë³´ ì¶”ê°€
        if note_type == "hold" and duration_seconds:
            note.update({
                "duration_seconds": round(duration_seconds, 2),
                "duration_milliseconds": round(duration_seconds * 1000),
                "duration_samples": round(duration_seconds * self.sample_rate)
            })
            
        # ë°•ì ì •ë³´ (í•„ìš”ì‹œ)
        if beat_index >= 0:
            note.update({
                "beat_position": (beat_index % 4) + 1,
                "is_strong_beat": (beat_index % 4) in [0, 2],
                "is_downbeat": (beat_index % 4) == 0
            })
        
        return note
    
    def _get_professional_lane_placement(self, time_seconds, intensity, level, source):
        """ì „ë¬¸ì ì¸ ë ˆì¸ ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜"""
        # ìŒì•…ì  ë§¥ë½ì„ ê³ ë ¤í•œ ë ˆì¸ ë°°ì¹˜
        
        # ê°•í•œ ìŒì€ ì¤‘ì•™ ë ˆì¸ ì„ í˜¸
        if intensity > 0.8:
            return 1  # ì¤‘ì•™
        elif intensity > 0.6:
            return 2  # ì¤‘ì•™ ìš°ì¸¡
        
        # ì‹œê°„ì— ë”°ë¥¸ íŒ¨í„´ ë³€í™”
        time_pattern = int(time_seconds / 8) % 3  # 8ì´ˆë§ˆë‹¤ íŒ¨í„´ ë³€í™”
        
        if time_pattern == 0:  # ì´ˆê¸°: ë‹¨ìˆœ íŒ¨í„´
            return 0 if intensity < 0.5 else 1
        elif time_pattern == 1:  # ì¤‘ê¸°: ì¢Œìš° êµëŒ€
            return 0 if (int(time_seconds * 2) % 2) == 0 else 3
        else:  # í›„ê¸°: ë‹¤ì–‘í•œ ë°°ì¹˜
            return int((time_seconds * intensity * 4)) % 4
    
    def _is_good_spacing(self, current_time, existing_notes, min_gap=0.12):
        """ì ì ˆí•œ ë…¸íŠ¸ ê°„ê²© í™•ì¸ (ì˜¤ë²„ì°¨íŒ… ë°©ì§€)"""
        if not existing_notes:
            return True
        
        for note in existing_notes[-3:]:  # ìµœê·¼ 3ê°œ ë…¸íŠ¸ë§Œ ê²€ì‚¬
            if abs(note["time_seconds"] - current_time) < min_gap:
                return False
        return True
    
    def _remove_overlapping_notes(self, notes):
        """ì¤‘ë³µ/ê²¹ì¹˜ëŠ” ë…¸íŠ¸ ì œê±°"""
        if not notes:
            return notes
            
        filtered_notes = [notes[0]]
        
        for note in notes[1:]:
            # ì§ì „ ë…¸íŠ¸ì™€ ì‹œê°„ ì°¨ì´ í™•ì¸
            if abs(note["time_seconds"] - filtered_notes[-1]["time_seconds"]) >= 0.08:
                filtered_notes.append(note)
            else:
                # ë” ê°•í•œ ë…¸íŠ¸ë¥¼ ì„ íƒ
                if note["intensity"] > filtered_notes[-1]["intensity"]:
                    filtered_notes[-1] = note
        
        return filtered_notes
    
    def _create_professional_chart_data(self, tempo, sr, notes, mp3_filename, musical_elements):
        """ì „ë¬¸ì ì¸ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        
        # ë‚œì´ë„ë³„ í†µê³„
        level_stats = {}
        for level in [1, 2, 3]:
            level_notes = [n for n in notes if n["level"] == level]
            level_stats[f"level_{level}_notes"] = len(level_notes)
        
        # ì†ŒìŠ¤ë³„ í†µê³„  
        source_stats = {}
        sources = set(note.get("source", "unknown") for note in notes)
        for source in sources:
            source_notes = [n for n in notes if n.get("source") == source]
            source_stats[f"{source}_notes"] = len(source_notes)
        
        return {
            "metadata": {
                "title": "Professional Rhythm Chart",
                "description": "ì „ë¬¸ ë¦¬ë“¬ê²Œì„ ì›ì¹™ ê¸°ë°˜ ì°¨íŠ¸",
                "generator": "ProfessionalRhythmNoteGenerator v2.0",
                "audio_file": mp3_filename,
                "design_principles": [
                    "ê°•í•œ ë¹„íŠ¸(ë“œëŸ¼/ë² ì´ìŠ¤) ì¤‘ì‹¬ ë°°ì¹˜",
                    "ì˜¤ë²„ì°¨íŒ… ë°©ì§€ ë° ìŒì•…ì„± ê°•ì¡°", 
                    "í™€ë“œ ë…¸íŠ¸ë¡œ ì§€ì†ìŒ í‘œí˜„",
                    "ë‚œì´ë„ë³„ íŒ¨í„´ ë³µì¡ë„ ì¡°ì ˆ",
                    "ì´ì§€ ëª¨ë“œ ë¦¬ë“¬ê° ë³´ì¥",
                    "ìŒì•…ì  í‘œí˜„ ê°•í™”",
                    "ë³´ì»¬ êµ¬ì—­ ìë™ ë¶„ë¥˜ (vocal, sub_vocal, rap, ttaechang)"
                ]
            },
            "timing": {
                "bpm": tempo,
                "sample_rate": sr,
                "beat_interval_ms": round(60000 / tempo)
            },
            "vocal_sections": musical_elements.get('vocal_sections', []),
            "notes": notes,
            "stats": {
                "total_notes": len(notes),
                **level_stats,
                **source_stats
            },
            "difficulty_info": {
                "easy": {
                    "description": "í•µì‹¬ ë¦¬ë“¬ë§Œ, ì¶©ë¶„í•œ ë¦¬ë“¬ê° ë³´ì¥",
                    "note_count": level_stats.get("level_1_notes", 0),
                    "focus": "ë“œëŸ¼/ë² ì´ìŠ¤ ê°•ì¡°, ê°•ë°• ì¤‘ì‹¬"
                },
                "medium": {
                    "description": "ë©œë¡œë”” ë ˆì´ì–´ ì¶”ê°€", 
                    "note_count": level_stats.get("level_1_notes", 0) + level_stats.get("level_2_notes", 0),
                    "focus": "ë¦¬ë“¬ + ë©œë¡œë”” ê°•ì¡°"
                },
                "hard": {
                    "description": "ëª¨ë“  ìŒì•…ì  ìš”ì†Œ í¬í•¨",
                    "note_count": len(notes),
                    "focus": "ë³µì¡í•œ íŒ¨í„´ + ë³´ì»¬ ì•¡ì„¼íŠ¸"
                }
            }
        }
    
    def _get_output_filename(self, mp3_file_path):
        """ì¶œë ¥ íŒŒì¼ëª… ìƒì„± - MP3 íŒŒì¼ëª…ê³¼ ë™ì¼í•˜ê²Œ"""
        base_name = os.path.splitext(os.path.basename(mp3_file_path))[0]
        return f"{base_name}.json"
    
    def _print_note_analysis_summary(self, notes, tempo, duration, vocal_sections=None):
        """ë…¸íŠ¸ ë¶„ì„ ê²°ê³¼ ìƒì„¸ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š NOTE ANALYSIS SUMMARY")
        print("="*60)
        
        # ê¸°ë³¸ í†µê³„
        total_notes = len(notes)
        notes_per_second = total_notes / duration if duration > 0 else 0
        print(f"ğŸµ ì´ ë…¸íŠ¸ ìˆ˜: {total_notes}ê°œ")
        print(f"â±ï¸  ë…¸íŠ¸ ë°€ë„: {notes_per_second:.2f}ê°œ/ì´ˆ")
        print(f"ğŸ¼ í‰ê·  BPM: {tempo:.1f}")
        
        # ë‚œì´ë„ë³„ ë¶„ì„
        level_stats = {}
        for level in [1, 2, 3]:
            level_notes = [n for n in notes if n["level"] == level]
            level_stats[level] = level_notes
        
        print(f"\nğŸ“ˆ ë‚œì´ë„ë³„ ë…¸íŠ¸ ë¶„í¬:")
        level_names = {1: "Easy", 2: "Medium", 3: "Hard"}
        for level in [1, 2, 3]:
            count = len(level_stats[level])
            percentage = (count / total_notes * 100) if total_notes > 0 else 0
            print(f"   {level_names[level]:6}: {count:3}ê°œ ({percentage:4.1f}%)")
        
        # í”¼ì¹˜ ì—°ê´€ì„± ë¶„ì„ (ë ˆì¸ ë¶„í¬)
        print(f"\nğŸ›£ï¸  í”¼ì¹˜ ì—°ê´€ì„± (ë ˆì¸ ë¶„í¬):")
        lane_names = {0: "Low (ì™¼ìª½)", 1: "Mid-Low", 2: "Mid-High", 3: "High (ì˜¤ë¥¸ìª½)"}
        lanes = {}
        for note in notes:
            lane = note.get("lane", 0)
            lanes[lane] = lanes.get(lane, 0) + 1
        
        for lane in sorted(lanes.keys()):
            count = lanes[lane]
            percentage = (count / total_notes * 100) if total_notes > 0 else 0
            name = lane_names.get(lane, f"Lane {lane}")
            print(f"   {name:12}: {count:3}ê°œ ({percentage:4.1f}%)")
        
        # ë…¸íŠ¸ íƒ€ì…ë³„ ë¶„ì„
        print(f"\nğŸ¯ ë…¸íŠ¸ íƒ€ì… ë¶„ì„:")
        tap_notes = [n for n in notes if n.get("type", "tap") == "tap"]
        hold_notes = [n for n in notes if n.get("type") == "hold"]
        print(f"   Tap Notes : {len(tap_notes):3}ê°œ ({len(tap_notes)/total_notes*100:4.1f}%)")
        print(f"   Hold Notes: {len(hold_notes):3}ê°œ ({len(hold_notes)/total_notes*100:4.1f}%)")
        
        # ì†ŒìŠ¤ë³„ ë¶„ì„
        print(f"\nğŸ¼ ë…¸íŠ¸ ìƒì„± ì†ŒìŠ¤ ë¶„ì„:")
        sources = {}
        for note in notes:
            source = note.get("source", "unknown")
            sources[source] = sources.get(source, 0) + 1
        
        source_names = {
            "core_rhythm": "í•µì‹¬ ë¦¬ë“¬",
            "sustain_hold": "ì§€ì†ìŒ í™€ë“œ",
            "melody_accent": "ë©œë¡œë”” ê°•ì¡°",
            "vocal_accent": "ë³´ì»¬ ì•¡ì„¼íŠ¸",
            "dynamic_accent": "ë‹¤ì´ë‚˜ë¯¹ ê°•ì¡°"
        }
        
        for source, count in sorted(sources.items()):
            name = source_names.get(source, source)
            percentage = (count / total_notes * 100) if total_notes > 0 else 0
            print(f"   {name:12}: {count:3}ê°œ ({percentage:4.1f}%)")
        
        # ë ˆì¸ ë¶„í¬ ë¶„ì„
        print(f"\nğŸ›£ï¸  ë ˆì¸ ë¶„í¬ ë¶„ì„:")
        lanes = {}
        for note in notes:
            lane = note.get("lane", 0)
            lanes[lane] = lanes.get(lane, 0) + 1
        
        for lane in sorted(lanes.keys()):
            count = lanes[lane]
            percentage = (count / total_notes * 100) if total_notes > 0 else 0
            print(f"   Lane {lane}: {count:3}ê°œ ({percentage:4.1f}%)")
        
        # ë³´ì»¬ êµ¬ì—­ ë¶„ì„ ì¶”ê°€
        if vocal_sections:
            print(f"\nğŸ¤ ë³´ì»¬ êµ¬ì—­ ë¶„ì„:")
            vocal_types = {}
            total_duration = 0
            for section in vocal_sections:
                section_type = section['type']
                duration = section['end_time'] - section['start_time']
                vocal_types[section_type] = vocal_types.get(section_type, 0) + duration
                total_duration += duration
            
            type_names = {
                'vocal': 'ë©”ì¸ ë³´ì»¬',
                'sub_vocal': 'ì„œë¸Œ ë³´ì»¬', 
                'rap': 'ë©',
                'ttaechang': 'ë•Œì°½/ì½”ëŸ¬ìŠ¤'
            }
            
            for vocal_type, total_time in sorted(vocal_types.items()):
                name = type_names.get(vocal_type, vocal_type)
                percentage = (total_time / total_duration * 100) if total_duration > 0 else 0
                print(f"   {name:12}: {total_time:5.1f}ì´ˆ ({percentage:4.1f}%)")
            
            print(f"   ì´ ë³´ì»¬ ì‹œê°„: {total_duration:.1f}ì´ˆ ({len(vocal_sections)}ê°œ êµ¬ê°„)")
        
        # ê°•ë„ ë¶„ì„
        intensities = [n.get("intensity", 0) for n in notes]
        if intensities:
            avg_intensity = sum(intensities) / len(intensities)
            max_intensity = max(intensities)
            min_intensity = min(intensities)
            print(f"\nğŸ’ª ê°•ë„ ë¶„ì„:")
            print(f"   í‰ê·  ê°•ë„: {avg_intensity:.3f}")
            print(f"   ìµœëŒ€ ê°•ë„: {max_intensity:.3f}")
            print(f"   ìµœì†Œ ê°•ë„: {min_intensity:.3f}")
        
        # íƒ€ì´ë° ê°„ê²© ë¶„ì„
        if len(notes) > 1:
            time_gaps = []
            for i in range(1, len(notes)):
                gap = notes[i]["time_seconds"] - notes[i-1]["time_seconds"]
                time_gaps.append(gap)
            
            avg_gap = sum(time_gaps) / len(time_gaps)
            min_gap = min(time_gaps)
            max_gap = max(time_gaps)
            
            print(f"\nâ° ë…¸íŠ¸ ê°„ê²© ë¶„ì„:")
            print(f"   í‰ê·  ê°„ê²©: {avg_gap:.3f}ì´ˆ")
            print(f"   ìµœì†Œ ê°„ê²©: {min_gap:.3f}ì´ˆ")
            print(f"   ìµœëŒ€ ê°„ê²©: {max_gap:.3f}ì´ˆ")
        
        # ì „ë¬¸ì„± ê²€ì¦
        print(f"\nâœ… ì „ë¬¸ ì›ì¹™ ì ìš© ê²€ì¦:")
        
        # 1. ê°•í•œ ë¹„íŠ¸ ë¹„ìœ¨
        strong_beat_notes = [n for n in notes if n.get("is_strong_beat", False) or n.get("is_downbeat", False)]
        strong_beat_ratio = len(strong_beat_notes) / total_notes if total_notes > 0 else 0
        print(f"   ê°•í•œ ë¹„íŠ¸ ë¹„ìœ¨: {strong_beat_ratio*100:.1f}% ({'âœ“' if strong_beat_ratio > 0.4 else 'âš ï¸'})")
        
        # 2. ì˜¤ë²„ì°¨íŒ… í™•ì¸ (ìµœì†Œ ê°„ê²© ì²´í¬)
        overcharting_safe = min(time_gaps) >= 0.08 if time_gaps else True
        print(f"   ì˜¤ë²„ì°¨íŒ… ë°©ì§€: {'âœ“' if overcharting_safe else 'âš ï¸'} (ìµœì†Œê°„ê²©: {min(time_gaps):.3f}ì´ˆ)" if time_gaps else "   ì˜¤ë²„ì°¨íŒ… ë°©ì§€: âœ“")
        
        # 3. ì´ì§€ ëª¨ë“œ ë¦¬ë“¬ê° (ì ì • ë²”ìœ„: 0.3~1.0ê°œ/ì´ˆ)
        easy_notes = level_stats[1]
        easy_density = len(easy_notes) / duration if duration > 0 else 0
        rhythm_good = 0.3 <= easy_density <= 1.0  # ì ì • ë²”ìœ„
        density_status = "âœ“" if rhythm_good else ("âš ï¸ ë„ˆë¬´ ë§ìŒ" if easy_density > 1.0 else "âš ï¸ ë„ˆë¬´ ì ìŒ")
        print(f"   Easy ë¦¬ë“¬ê°: {density_status} ({easy_density:.2f}ê°œ/ì´ˆ)")
        
        # 4. í™€ë“œ ë…¸íŠ¸ í™œìš©
        has_holds = len(hold_notes) > 0
        print(f"   í™€ë“œ ë…¸íŠ¸ í™œìš©: {'âœ“' if has_holds else '-'} ({len(hold_notes)}ê°œ)")
        
        # 5. ì¸ê°„ ê³µí•™ì  ì œì•½ ë¶„ì„ (ì­ íŒ¨í„´ ì²´í¬)
        jack_count = self._analyze_jack_patterns(notes)
        jack_ratio = jack_count / total_notes if total_notes > 0 else 0
        jack_safe = jack_ratio < 0.1  # 10% ë¯¸ë§Œì´ë©´ ì•ˆì „
        print(f"   ì­ íŒ¨í„´ ìµœì†Œí™”: {'âœ“' if jack_safe else 'âš ï¸'} ({jack_count}ê°œ, {jack_ratio*100:.1f}%)")
        
        # 6. í”¼ì¹˜ ì—°ê´€ì„± í’ˆì§ˆ
        pitch_variance = self._analyze_pitch_relevancy_quality(notes)
        pitch_good = pitch_variance > 0.3  # ì¶©ë¶„í•œ ë ˆì¸ ë‹¤ì–‘ì„±
        print(f"   í”¼ì¹˜ ì—°ê´€ì„±: {'âœ“' if pitch_good else 'âš ï¸'} (ë ˆì¸ ë¶„ì‚°ë„: {pitch_variance:.2f})")
        
        print("="*60)
        print("ğŸ¯ Advanced Rhythm Chart Analysis Complete!")
        print("="*60)
    
    def _analyze_jack_patterns(self, notes):
        """ì­ íŒ¨í„´ ë¶„ì„ - ê°™ì€ ë ˆì¸ì˜ ì—°ì† ë…¸íŠ¸"""
        jack_count = 0
        sorted_notes = sorted(notes, key=lambda x: x["time_seconds"])
        
        for i in range(1, len(sorted_notes)):
            prev_note = sorted_notes[i-1]
            curr_note = sorted_notes[i]
            
            # ê°™ì€ ë ˆì¸ì—ì„œ 0.3ì´ˆ ì´ë‚´ ì—°ì† ë…¸íŠ¸ëŠ” ì­ìœ¼ë¡œ ê°„ì£¼
            if (prev_note.get("lane") == curr_note.get("lane") and 
                curr_note["time_seconds"] - prev_note["time_seconds"] < 0.3):
                jack_count += 1
        
        return jack_count
    
    def _analyze_pitch_relevancy_quality(self, notes):
        """í”¼ì¹˜ ì—°ê´€ì„± í’ˆì§ˆ ë¶„ì„ - ë ˆì¸ ë¶„ì‚°ë„"""
        lanes = [note.get("lane", 0) for note in notes]
        if not lanes:
            return 0
        
        # ë ˆì¸ ë¶„ì‚°ë„ ê³„ì‚° (0~1, ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•¨)
        lane_counts = {}
        for lane in lanes:
            lane_counts[lane] = lane_counts.get(lane, 0) + 1
        
        total_notes = len(lanes)
        variance = 0
        for count in lane_counts.values():
            ratio = count / total_notes
            variance += ratio * (1 - ratio)
        
        return variance

    def _save_chart(self, chart, filename):
        """ì°¨íŠ¸ ë°ì´í„° ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(chart, f, indent=2, ensure_ascii=False)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) != 2:
        print("Usage: python note_generator_improved.py <mp3_file_path>")
        sys.exit(1)
    
    mp3_file = sys.argv[1]
    
    try:
        generator = ProfessionalRhythmNoteGenerator()
        output_file = generator.generate_notes(mp3_file)
        print(f"\nğŸ¯ Professional Chart Generated: {output_file}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()