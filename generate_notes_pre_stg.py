import librosa
import numpy as np
import json
import os

def analyze_audio_and_generate_notes(audio_path, output_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•´ì„œ ë¦¬ë“¬ê²Œì„ ë…¸íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±"""
    print(f"ğŸµ Analyzing audio: {audio_path}")
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_path)
    duration = librosa.get_duration(y=y, sr=sr)
    
    print(f"ğŸ“Š Duration: {duration:.2f} seconds")
    print(f"ğŸ“Š Sample rate: {sr} Hz")
    
    # BPM ê°ì§€
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
    beat_times = librosa.beat.beat_track(y=y, sr=sr, units='time')[1]
    
    print(f"ğŸ¥ Detected BPM: {tempo:.2f}")
    print(f"ğŸ¯ Found {len(beat_times)} beats")
    
    # ìŒì„±/ë³´ì»¬ ê°ì§€ë¥¼ ìœ„í•œ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
    stft = librosa.stft(y)
    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    
    # ì—ë„ˆì§€ ê°ì§€
    rms_energy = librosa.feature.rms(y=y)[0]
    
    # Onset ê°ì§€ (ìŒì˜ ì‹œì‘ì )
    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, units='time')
    print(f"ğŸ¶ Found {len(onset_frames)} onsets")
    
    # ë…¸íŠ¸ ìƒì„±
    notes = []
    
    # 1. ê¸°ë³¸ ë°•ì ê¸°ë°˜ ë…¸íŠ¸ (ì£¼ ë¦¬ë“¬)
    for i, beat_time in enumerate(beat_times):
        if beat_time < duration - 0.5:  # ëë¶€ë¶„ ì—¬ìœ 
            # ê°•ë°•ê³¼ ì•½ë°• êµ¬ë¶„
            is_strong_beat = i % 4 == 0  # 4/4ë°•ì ê°€ì •
            intensity = 0.8 if is_strong_beat else 0.6
            
            notes.append({
                "time_seconds": float(beat_time),
                "lane": 0,
                "type": "beat",
                "intensity": float(intensity)
            })
    
    # 2. Onset ê¸°ë°˜ ì¶”ê°€ ë…¸íŠ¸ (ë©œë¡œë””/íš¨ê³¼ìŒ)
    onset_threshold = np.percentile(rms_energy, 70)  # ìƒìœ„ 30% ì—ë„ˆì§€ë§Œ
    
    for onset_time in onset_frames:
        if onset_time < duration - 0.5:
            # ê¸°ì¡´ ë°•ìì™€ ë„ˆë¬´ ê°€ê¹Œìš´ onsetì€ ì œì™¸
            too_close = any(abs(onset_time - note["time_seconds"]) < 0.1 
                          for note in notes)
            
            if not too_close:
                # í•´ë‹¹ ì‹œê°„ì˜ ì—ë„ˆì§€ ë ˆë²¨ í™•ì¸
                frame_idx = int(onset_time * sr / 512)  # hop_length=512 ê¸°ë³¸ê°’
                if frame_idx < len(rms_energy):
                    energy = rms_energy[frame_idx]
                    if energy > onset_threshold:
                        notes.append({
                            "time_seconds": float(onset_time),
                            "lane": 1,
                            "type": "melody",
                            "intensity": float(min(energy * 2, 1.0))
                        })
    
    # 3. ê³ ì£¼íŒŒ ì´ë²¤íŠ¸ ê°ì§€ (ì‹¬ë²Œ, í•˜ì´í–‡ ë“±)
    high_freq_onsets = librosa.onset.onset_detect(
        y=y, sr=sr, units='time', 
        fmin=2000, fmax=8000  # ê³ ì£¼íŒŒ ëŒ€ì—­
    )
    
    for onset_time in high_freq_onsets:
        if onset_time < duration - 0.5:
            # ë‹¤ë¥¸ ë…¸íŠ¸ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
            too_close = any(abs(onset_time - note["time_seconds"]) < 0.15 
                          for note in notes)
            
            if not too_close:
                notes.append({
                    "time_seconds": float(onset_time),
                    "lane": 2,
                    "type": "high",
                    "intensity": 0.7
                })
    
    # ì‹œê°„ìˆœ ì •ë ¬
    notes.sort(key=lambda x: x["time_seconds"])
    
    # ë…¸íŠ¸ ë°ì´í„° êµ¬ì¡°
    note_data = {
        "metadata": {
            "title": "pre stg_re_128 Rhythm Chart",
            "description": "ë°•ì ê¸°ë°˜ ë…¸íŠ¸ + ë©œë¡œë”” ê°ì§€",
            "generator": "RhythmGameNoteGenerator v1.0",
            "audio_file": "pre stg_re_128.mp3"
        },
        "timing": {
            "bpm": float(tempo),
            "sample_rate": int(sr),
            "duration_seconds": float(duration)
        },
        "notes": notes
    }
    
    # JSON íŒŒì¼ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(note_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Generated {len(notes)} notes")
    print(f"ğŸ’¾ Saved to: {output_path}")
    
    # í†µê³„ ì¶œë ¥
    beat_notes = [n for n in notes if n["type"] == "beat"]
    melody_notes = [n for n in notes if n["type"] == "melody"]
    high_notes = [n for n in notes if n["type"] == "high"]
    
    print(f"ğŸ“Š Note breakdown:")
    print(f"   - Beat notes: {len(beat_notes)}")
    print(f"   - Melody notes: {len(melody_notes)}")
    print(f"   - High freq notes: {len(high_notes)}")
    
    return note_data

if __name__ == "__main__":
    audio_file = "/Users/deathcry/Work/RockStarter/audio_analyzer/pre stg_re_128.mp3"
    output_file = "/Users/deathcry/Work/RockStarter/pre-stg-re-128.json"
    
    if not os.path.exists(audio_file):
        print(f"âŒ Audio file not found: {audio_file}")
        exit(1)
    
    try:
        note_data = analyze_audio_and_generate_notes(audio_file, output_file)
        print("ğŸ® Note generation complete!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        exit(1)